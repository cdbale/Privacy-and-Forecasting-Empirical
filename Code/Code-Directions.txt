CODE DIRECTIONS

---

CODE FOR SIMULATIONS

R files `simulation-accuracy-privacy-weighted-euclidean.R` and `simulation-accuracy-privacy-weighted-euclidean-large-N.R`
are used to obtain the simulation results. Simulation Plots used in the paper will be saved to the `Outputs/Figures/Simulation/` folder. 
The code in the simulation files was written to work with the functions defined in the simulation files. Some of these functions (particularly the
knts_alg() function) were re-written in the `knts_helper_functions.R` file to reduce execution time when running on larger data sets in later code files.

Note: due to the randomness of the simulation algorithm, the numerical results will vary from run to run. However, the substantive conclusions mentioned in
the paper remain the same.

---

CODE FOR ANALYZING M3 DATA

Create a `Data` folder in the main repository directory. This is ignored when pushing to the repo for storage limitation reasons.

Create an `M3` folder in the `Data` directory.

Download the M3 data sets (-monthly, -other, -quarterly, -yearly) and place them in the `M3` folder created as a subdirectory of the `Data` folder. Link to data download: https://drive.google.com/drive/folders/1VG_G2vethsJQLRFv1uNuPZFYe0K-Y_ku?usp=sharing.

All python and R code files are found in the Code/Analysis subdirectory. Python files can be run using a command prompt (we used Anaconda Powershell Prompt).

1. Run `Data_Cleaning_M3.py`. This creates the train and test data for the original M3 data set, and stores it in the `/Cleaned/M3/` subdirectory of the `Data` folder.
	Note that there are four files for each data frequency/domain: two training files (one each for forecasting the last and second to last points of each time series) and two test data files containing the actual data for the forecasted periods.

2. Run `Create_AN_DP_M3.py`. This creates protected versions of each of the M3 training data files using additive noise or differential privacy for the parameter values in the paper. Note that this file also creates the file `M3_computation_time.csv` which tracks the computation time of the various steps involved in the k-nTS+ protection process. This file is found at `/Data/Computation_Time/M3_computation_time.csv`.

3. Run `Forecast_for_Feature_Selection_M3.py`. This generates forecasts and measures the series level absolute errors for the original and baseline protected data sets for the last time period assumed available to
	the data owner (h2). The forecast errors will be predicted using the corresponding time series features in the feature selection methodology in k-nTS+. The file `Forecast_for_Feature_Selection_M3.py` has a dictionary `forecasting_models` where the various forecasting models and some of their arguments/options are specified. The `use_gpu` option for the RNN model should be set to `True` only if you have an Nvidia gpu with the cuda (https://developer.nvidia.com/cuda-toolkit) and torch (https://pytorch.org/get-started/locally/) packages installed. The default for `use_gpu` is set to `False` (the CPU is used to train the RNN model(s)).
	
4. Run `k-nts_M3.R` which protects the M3 data using k-nTS based on manual feature selection. See the paper for discussion of the chosen features.

5. Run `original_and_baseline_tsfeatures_extraction_M3.R`. This R script calculates the time series features for the original and baseline protected M3 data sets. These features will be combined with the forecast errors from step 3. to be used in the machine learning-based feature selection method in k-nTS+. Note that all features are saved to the `Data/Features/` folder.

6. Run `k-nts-plus_M3.R` which protects the M3 data using the k-nTS+ methodology based on the machine-learning based feature selection method. The runtime of this file in particular benefits from high core-count CPUs as the random forest models are trained in parallel.

7. Run `k-nts_plus_M3_bounded_M.R` which creates modified versions of the k-nTS+ (k = 3) protected data sets by bounding the differences between the protected and unprotected values, as discussed in the paper.

8. Run `Final_Forecasts_M3.py`. This generates forecasts and measures the series level absolute errors for the final original and protected data sets.

9. Run `VAR_weight_forecasts_M3.py` to generate VAR model forecasts based on simulated VAR series and protected lagged values.

10. Run `updated_tsfeatures_extraction_M3.R` to extract time series features for the final unprotected and protected data sets.

11. Run `privacy_assessment_M3.R` to perform the identification disclosure simulation. Results are saved in an .csv file `overall_privacy_averages.csv` in the "Outputs/Results/M3/Tables/" directory.

12. Run `forecast_privacy_assessment_M3.R` to perform the forecast identification disclosure simulation. Results are saved as `weighted_fcast_prop_ident.csv` (for all non-VAR-based methods) and `weighted_var_fcast_prop_ident.csv` (for VAR-based methods). These files are saved to the same directory listed in Step 11.

13. Run `magnitude_computation_M3.R` to compute the magnitude of time series based on the test data (actual value from forecasted time period). Results are saved in the `Data/Magnitudes/` subdirectory.

14. Run `results_computation_M3.R` to compute the accuracy results. Results are saved to several files in the `Outputs/Results/M3/Tables` subdirectory.
	- `avg_accuracy_by_protection.csv`: gives the original and protected mean accuracy and the percent change in mean accuracy (across all models and data sets).
	- `var_avg_accuracy_by_protection.csv`: same as above but for the VAR-simulated and VAR protected lag results.
	- `avg_accuracy_by_magnitude_protection.csv`: mean accuracy results broken down by large vs. small magnitude time series for each model and data set.
	- `var_avg_accuracy_by_magnitude_protection.csv`: same as above but for the VAR-simulated and VAR protected lag results.
	- `averages_by_model.csv`: mean accuracy results under bounded k-nTS+ (k=3, M=1.5) across all data sets for each forecasting model
	- `averages_by_data.csv`: mean accuracy results for each data subset and privacy method

15. Run `computation_time_analysis.R` to analyze the computation time of the k-nTS+ process. The regression results used in the paper are printed to the R console, and the plot (Figure XXX) is saved to the `Outputs/Figures/M3/` directory.





PUT IN SOMETHING ABOUT THE SLIGHT RANDOMNESS OF RESULTS FROM TRAINING RNN MODELS? LGBM MODELS? AUTO-ARIMA?






# Steps for M3 rate data

1. Run `Data_Cleaning_M3_rate.py`. Same as step 1. above but for the M3 rates.

2. Run `Create_AN_DP_M3_rate.py`. Same as step 2. above but for the M3 rates.

3. Run `Forecast_for_Feature_Selection_M3_rate.py`. Same as step 3. above but for the M3 rates.

4. Run `k-nts_M3_rate.R`. Same as step 4. above but for the M3 rates.

5. Run `original_and_baseline_tsfeatures_extraction_M3_rate.R`. Same as step 4. above but for the M3 rates.

6. Run `k-nts-plus_M3_rate.R`. Same as above but for M3 rates.

7. Run `k-nts_plus_M3_rate_bounded_M.R`. Same as above but for M3 rates.

8. Run `Final_Forecasts_M3_rate.py`. Same as above but for M3 rates.

9. Run `VAR_weight_forecasts_M3_rate.py`. Same as above but for M3 rates.

10. Run `updated_tsfeatures_extraction_M3_rate.R` Same as above but for the M3 rate data.

11. Run `privacy_assessment_M3_rate.R` to perform the identification disclosure simulation. Results are saved to "Outputs/Results/M3_rate/Tables/".

12. Run `forecast_privacy_assessment_M3_rate.R` to perform the forecast identification disclosure simulation. Results are saved to "Outputs/Results/M3/Tables".

13. Run `results_computation_M3_rate.R` to compute the accuracy results. Results are saved to.......









########## Steps for M4 data ##########

Download the M4 data sets. They can be found at the following link: https://drive.google.com/drive/folders/1m84cDf9IzF4sTtvPBvvDKi-GEAaPfw-7?usp=sharing. 

Create an folder `M4` inside the `Data` directory of the repository. Place the `Train` and `Test` folders from the above link in the `M4` folder.

1. Run `Data_Cleaning_M4.py`.

2. Run `Create_DP_M4.py`.

3. Run `Forecast_for_Feature_Selection_M4.py`. Same as step 3. above but for the M4 data.

4. Run `original_and_baseline_tsfeatures_extraction_M4.R`. Same as step 4. above but for the M4 data.

5. Run `k-nts_plus_M4.R`.

6. Run `k-nts_plus_M4_bounded_M.R`.

7. Run `Final_Forecasts_M4.py`. Same as above but for M4.

8. Run `privacy_assessment_M4.R` to perform the identification disclosure simulation. Results are saved to "Outputs/Results/M4/Tables/".















9. Run `forecast_privacy_assessment_M4.R` to perform the forecast identification disclosure simulation. Results are saved to "Outputs/Results/M4/Tables".

8. ....









# Steps for M4 rate data

1. Run `Data_Cleaning_M4_rate.py`.

2. Run `Create_DP_M4_rate.py`. Same as step 2. above but for the M4 data.

3. Run `Forecast_for_Feature_Selection_M4_rate.py`. Same as step 3. above but for the M4 data.

4. Run `original_and_baseline_tsfeatures_extraction_M4_rate.R`. Same as step 4. above but for the M4 data.

5. Run `k-nts_plus_M4_rate.R`.

6. Run `k-nts_plus_M4_rate_bounded_M.R`.

7. Run `Final_Forecasts_M4_rate.py`. Same as above but for M4 rate data.

8. Run `privacy_assessment_M4_rate.R` to perform the identification disclosure simulation. Results are saved to "Outputs/Results/M4/Tables/".












9. Run `forecast_privacy_assessment_M4_rate.R` to perform the forecast identification disclosure simulation. Results are saved to "Outputs/Results/M4/Tables".

10. ....


CHECK THAT EACH STEP USES THE CORRECT SEASONAL IDENTIFIERS
*check that window length used is consistent from k-nTS files to k-nTS+ files
