{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140e4576",
   "metadata": {},
   "source": [
    "# Code for Multivariate LGBM Implementation - testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a890162",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6394ead",
   "metadata": {},
   "source": [
    "Use cross-validation to evaluate a set of parameters - compare cross validation results for different parameter combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc8eb28",
   "metadata": {},
   "source": [
    "## Steps to implement:\n",
    "\n",
    "* ~~max epochs and initial learning rate set to 1200 and 0.075. - not going to mess with these, just use defaults~~\n",
    "* ~~MAE as loss function in model training?~~\n",
    "\n",
    "* ~~k-folds cross validation for window length?~~\n",
    "* Direct modeling - train one LGBM model for every horizon step\n",
    "\n",
    "* ~~early stopping mechanism when validation error does not improve over 5 consecutive epochs. - only do about this if necessary.~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2227b804",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a56e51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecasting_functions import *\n",
    "from data_processing_functions import *\n",
    "import lightgbm as lgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34748e25",
   "metadata": {},
   "source": [
    "### Read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9e272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import weekly finance time series\n",
    "# ignore header and skip the first row to use integers as column names\n",
    "full_data = pd.read_csv(\"../../Data/Train/Clean/full_m3_monthly_micro_clean.csv\", header=None, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d98d2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to a list of series, potentially with different lengths\n",
    "full_data = [x.dropna() for _, x in full_data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e1228f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast horizon\n",
    "h = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5b29e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [x.iloc[:-h] for x in full_data]\n",
    "Test = [x.iloc[-h:] for x in full_data]\n",
    "Test = pd.DataFrame([x.reset_index(drop=True) for x in Test]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6279a3ac",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f614c2ff",
   "metadata": {},
   "source": [
    "### Perform reduction on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08a6b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dict = {\"windows\": {\"window_length\": 36}, \"deseasonalize\": {\"sp\": 12, \"seasonality_type\": \"additive\"}}\n",
    "\n",
    "Y_processed, last_window_dt, last_window, full_lags = pre_process(ts_data=Y,\n",
    "                                                                  target_forecast_period=h,\n",
    "                                                                  mean_normalize=True,\n",
    "                                                                  log=True,\n",
    "                                                                  sp=12,\n",
    "                                                                  transform_dict=transform_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f4cd6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0d892d",
   "metadata": {},
   "source": [
    "### Convert `Y_processed` Train and Validation Data for LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c988413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Y_processed.iloc[:,:-1]\n",
    "label = Y_processed.iloc[:,-1]\n",
    "train_data = lgb.Dataset(train, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dff1fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_data = train_data.create_valid(train, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1a8929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0b1a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.05, 0.1]\n",
    "num_boost_rounds = [100, 200]\n",
    "c = list(itertools.product(learning_rate, num_boost_rounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e731ec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.05, 100)\n",
      "(0.05, 200)\n",
      "(0.1, 100)\n",
      "(0.1, 200)\n"
     ]
    }
   ],
   "source": [
    "for p in c:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b65bebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\": \"mae\",\n",
    "          \"metrics\": \"mae\",\n",
    "          \"learning_rate\": 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cbdc7b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9180\n",
      "[LightGBM] [Info] Number of data points in the train set: 23310, number of used features: 36\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9180\n",
      "[LightGBM] [Info] Number of data points in the train set: 23310, number of used features: 36\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9180\n",
      "[LightGBM] [Info] Number of data points in the train set: 23310, number of used features: 36\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9180\n",
      "[LightGBM] [Info] Number of data points in the train set: 23310, number of used features: 36\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9180\n",
      "[LightGBM] [Info] Number of data points in the train set: 23310, number of used features: 36\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9180\n",
      "[LightGBM] [Info] Number of data points in the train set: 23310, number of used features: 36\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9180\n",
      "[LightGBM] [Info] Number of data points in the train set: 23310, number of used features: 36\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9180\n",
      "[LightGBM] [Info] Number of data points in the train set: 23310, number of used features: 36\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9180\n",
      "[LightGBM] [Info] Number of data points in the train set: 23310, number of used features: 36\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9180\n",
      "[LightGBM] [Info] Number of data points in the train set: 23310, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.000963\n",
      "[LightGBM] [Info] Start training from score -0.000285\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000260\n",
      "[LightGBM] [Info] Start training from score -0.000072\n",
      "[LightGBM] [Info] Start training from score -0.000540\n",
      "[LightGBM] [Info] Start training from score -0.000512\n",
      "[LightGBM] [Info] Start training from score -0.000037\n",
      "[LightGBM] [Info] Start training from score -0.000776\n",
      "[LightGBM] [Info] Start training from score -0.000345\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tcv_agg's l1: 0.111289 + 0.00260597\n"
     ]
    }
   ],
   "source": [
    "bst_vals = lgb.cv(params,\n",
    "                  train_data,\n",
    "                  num_boost_round=1000,\n",
    "                  nfold=10,\n",
    "                  stratified=False,\n",
    "                  callbacks=[lgb.early_stopping(stopping_rounds=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2a05299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9180\n",
      "[LightGBM] [Info] Number of data points in the train set: 25905, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.000476\n"
     ]
    }
   ],
   "source": [
    "bst = lgb.train(params, \n",
    "                train_data,\n",
    "                num_boost_round=1000)\n",
    "\n",
    "fcasts = bst.predict(last_window_dt)\n",
    "    \n",
    "fcasts = [pd.Series(x) for x in fcasts]\n",
    "    \n",
    "fcast_indexes = [last_window_dt[i].index[-1]+h for i in range(474)]\n",
    "    \n",
    "# add correct time index back to forecasts\n",
    "for i in range(474):\n",
    "    fcasts[i].index = [fcast_indexes[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "540ea574",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcasts = post_process(full_ts_data=Y,\n",
    "                      target_forecast_period=h,\n",
    "                      forecasts=fcasts,\n",
    "                      last_window_with_trend=last_window,\n",
    "                      mean_normalize=True,\n",
    "                      log=True,\n",
    "                      sp=12,\n",
    "                      transform_dict=transform_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ae782b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "648.4268112753832"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Test, fcasts, multioutput=\"uniform_average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3afa261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e370d918",
   "metadata": {},
   "source": [
    "## currently at train_and_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242bff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_lgbm_window_length(ts_data, h, param_grid):\n",
    "    num_series = len(ts_data)\n",
    "    \n",
    "    # set model parameters\n",
    "    params = {\"objective\": \"mae\",\n",
    "              \"metrics\": \"mae\"}\n",
    "    \n",
    "    # use cross-validation to choose best window length from param_grid\n",
    "    maes = []\n",
    "    \n",
    "    window_lengths = param_grid['window_length']\n",
    "\n",
    "    for w in window_lengths:\n",
    "\n",
    "        transform_dict = {\"windows\": {\"window_length\": w}, \"deseasonalize\": {\"sp\": 12, \"seasonality_type\": \"additive\"}}\n",
    "    \n",
    "        Y_processed, last_window_dt, last_window, full_lags = pre_process(ts_data=ts_data,\n",
    "                                                                          target_forecast_period=h,\n",
    "                                                                          mean_normalize=True,\n",
    "                                                                          log=True,\n",
    "                                                                          sp=12,\n",
    "                                                                          transform_dict=transform_dict)\n",
    "    \n",
    "        train = Y_processed.iloc[:,:-1]\n",
    "        label = Y_processed.iloc[:,-1]\n",
    "        train_data = lgb.Dataset(train, label=label)\n",
    "    \n",
    "        bst = lgb.cv(params,\n",
    "                     train_data,\n",
    "                     stratified=False)\n",
    "    \n",
    "        best_mae = bst['l1-mean'][-1]\n",
    "        maes.append(best_mae)\n",
    "        \n",
    "    which_best = np.argmin(maes)\n",
    "    \n",
    "    return window_lengths[which_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd28345",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_window_length = multivariate_lgbm_window_length(Y, h, param_grid={'window_length':[24, 36]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5150b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_window_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565caa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dict = {\"windows\": {\"window_length\": best_window_length}, \"deseasonalize\": {\"sp\": 12, \"seasonality_type\": \"additive\"}}\n",
    "\n",
    "Y_processed, last_window_dt, last_window, full_lags = pre_process(ts_data=Y,\n",
    "                                                                  target_forecast_period=h,\n",
    "                                                                  mean_normalize=True,\n",
    "                                                                  log=True,\n",
    "                                                                  sp=12,\n",
    "                                                                  transform_dict=transform_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a2bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_lgbm_forecast(ts_data, last_window_dt, num_series):\n",
    "    \"\"\"\n",
    "    Function to train multivariate lgbm model. Note that the hyperparameter (window_length) chosen using cross-validation\n",
    "    is part of the pre-processing. It is important that non-processed data is input into this function.\n",
    "    \"\"\"\n",
    "    # set model parameters\n",
    "    params = {\"objective\": \"mae\",\n",
    "              \"metrics\": \"mae\"}\n",
    "    \n",
    "    train = ts_data.iloc[:,:-1]\n",
    "    label = ts_data.iloc[:,-1]\n",
    "\n",
    "    train_data = lgb.Dataset(train, label=label)\n",
    "    \n",
    "    bst = lgb.train(params, train_data)\n",
    "    \n",
    "    fcasts = bst.predict(last_window_dt)\n",
    "    \n",
    "    fcasts = [pd.Series(x) for x in fcasts]\n",
    "    \n",
    "    fcast_indexes = [last_window_dt[i].index[-1]+h for i in range(num_series)]\n",
    "    \n",
    "    # add correct time index back to forecasts\n",
    "    for i in range(num_series):\n",
    "        fcasts[i].index = [fcast_indexes[i]]\n",
    "        \n",
    "    return fcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d823141",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcasts = multivariate_lgbm_forecast(Y_processed, last_window_dt, 474)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5fd080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = Y_processed.iloc[:,:-1]\n",
    "# label = Y_processed.iloc[:,-1]\n",
    "\n",
    "# train_data = lgb.Dataset(train, label=label)\n",
    "# # validation_data = train_data.create_valid(train, label)\n",
    "# # validation_data = lgb.Dataset('validation.svm', reference=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ba52ca",
   "metadata": {},
   "source": [
    "### Set Parameters for LGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\"objective\": \"mae\", \n",
    "#           \"metrics\": \"mae\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f874092c",
   "metadata": {},
   "source": [
    "### Run with 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dccbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bst = lgb.cv(params,\n",
    "#              train_data,\n",
    "#              stratified=False,\n",
    "#              callbacks=[lgb.early_stopping(stopping_rounds=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541723e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mae = np.min(bst['l1-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ee636",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = lgb.train(params, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f029da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcasts = bst.predict(last_window_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58698d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine forecasts into (num_series, horizon_length) shaped array\n",
    "# fcasts = np.concatenate([i.reshape(474, 1) for i in fcasts], axis=1)\n",
    "fcasts = [pd.Series(x) for x in fcasts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcast_indexes = [np.arange(last_window[i].index[-1]+1, last_window[i].index[-1]+h+1) for i in range(474)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f25a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add correct time index back to forecasts\n",
    "for i in range(474):\n",
    "    fcasts[i].index = fcast_indexes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae8c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcasts = post_process(full_ts_data=Y,\n",
    "                      forecasts=fcasts,\n",
    "                      last_window_with_trend=last_window,\n",
    "                      mean_normalize=True,\n",
    "                      log=True,\n",
    "                      sp=12,\n",
    "                      transform_dict=transform_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4640d0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(Test, fcasts, multioutput=\"uniform_average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c72c0c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd3162",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51c9dd0",
   "metadata": {},
   "source": [
    "### Use Cross-validation to choose window length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d4c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_lengths = [24, 30, 36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78767bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maes = []\n",
    "\n",
    "# for w in window_lengths:\n",
    "\n",
    "#     transform_dict = {\"windows\": {\"window_length\": w}, \"deseasonalize\": {\"sp\": 12, \"seasonality_type\": \"additive\"}}\n",
    "    \n",
    "#     Y_processed, last_window_dt, last_window, full_lags = pre_process(ts_data=Y,\n",
    "#                                                                       mean_normalize=True,\n",
    "#                                                                       log=True,\n",
    "#                                                                       sp=12,\n",
    "#                                                                       transform_dict=transform_dict)\n",
    "    \n",
    "#     train = Y_processed.iloc[:,:-1]\n",
    "#     label = Y_processed.iloc[:,-1]\n",
    "#     train_data = lgb.Dataset(train, label=label)\n",
    "    \n",
    "#     bst = lgb.cv(params,\n",
    "#                  train_data,\n",
    "#                  stratified=False)\n",
    "    \n",
    "#     best_mae = bst['l1-mean'][-1]\n",
    "#     maes.append(best_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7135cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "maes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_best = np.argmin(maes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cac0d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dict = {\"windows\": {\"window_length\": window_lengths[which_best]}, \"deseasonalize\": {\"sp\": 12, \"seasonality_type\": \"additive\"}}\n",
    "\n",
    "Y_processed, last_window_dt, last_window, full_lags = pre_process(ts_data=Y,\n",
    "                                                                  mean_normalize=True,\n",
    "                                                                  log=True,\n",
    "                                                                  sp=12,\n",
    "                                                                  transform_dict=transform_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Y_processed.iloc[:,:-1]\n",
    "label = Y_processed.iloc[:,-1]\n",
    "\n",
    "train_data = lgb.Dataset(train, label=label)\n",
    "# validation_data = train_data.create_valid(train, label)\n",
    "# validation_data = lgb.Dataset('validation.svm', reference=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b08641",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = lgb.train(params, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72902d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcasts = bst.predict(last_window_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7630625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine forecasts into (num_series, horizon_length) shaped array\n",
    "# fcasts = np.concatenate([i.reshape(474, 1) for i in fcasts], axis=1)\n",
    "fcasts = [pd.Series(x) for x in fcasts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a56317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcast_indexes = [np.arange(last_window[i].index[-1]+1, last_window[i].index[-1]+h+1) for i in range(474)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcast_indexes = [last_window[i].index[-1]+h for i in range(num_series)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add correct time index back to forecasts\n",
    "for i in range(474):\n",
    "    fcasts[i].index = fcast_indexes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41440321",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcasts = post_process(full_ts_data=Y,\n",
    "                      target_forecast_period=h,\n",
    "                      forecasts=fcasts,\n",
    "                      last_window_with_trend=last_window,\n",
    "                      mean_normalize=True,\n",
    "                      log=True,\n",
    "                      sp=12,\n",
    "                      transform_dict=transform_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8072ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(Test, fcasts, multioutput=\"uniform_average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d79c86",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acabe8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 18\n",
    "fcasts = [full_forecast_analysis(Y=Y,\n",
    "                                                     h=i,\n",
    "                                                     forecasting_model=\"Multivariate_LGBM\",\n",
    "                                                     window_length=None,\n",
    "                                                     make_stationary=False,\n",
    "                                                     seasonality_type=\"additive\",\n",
    "                                                     sp=12,\n",
    "                                                     remove_seasonality=True,\n",
    "                                                     mean_normalize=True,\n",
    "                                                     log=True,\n",
    "                                                     param_grid={'window_length':[30]}) for i in range(1, H+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1965a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine fcast dataframes into one\n",
    "fcasts = pd.concat(fcasts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac977fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2546fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(Test, fcasts, multioutput=\"uniform_average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7630e4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
