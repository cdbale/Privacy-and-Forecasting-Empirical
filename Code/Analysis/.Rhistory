all_protected_results <- all_protected_results %>%
filter(Model != "VAR" | Data != "yearly-MICRO")
all_original_results <- all_original_results %>%
filter(Model != "VAR" | Data != "yearly-MICRO")
var_protected_results <- var_protected_results %>%
filter(Model != "VAR" | Data != "yearly-MICRO")
if (file.exists(paste0("../../Outputs/Results/", data_folder, "Tables/"))){
write.csv(all_original_results, file=paste0("../../Outputs/Results/", data_folder, "Tables/all_original_results.csv"), row.names = FALSE)
write.csv(all_protected_results, file=paste0("../../Outputs/Results/", data_folder, "Tables/all_protected_results.csv"), row.names = FALSE)
} else {
dir.create(paste0("../../Outputs/Results/", data_folder, "Tables/"))
write.csv(all_original_results, file=paste0("../../Outputs/Results/", data_folder, "Tables/all_original_results.csv"), row.names = FALSE)
write.csv(all_protected_results, file=paste0("../../Outputs/Results/", data_folder, "Tables/all_protected_results.csv"), row.names = FALSE)
}
to_exclude <- all_protected_results %>%
group_by(Protection, Parameter, Model, Data) %>%
summarize(avg_AE = mean(values), .groups='drop') %>%
arrange(desc(avg_AE)) %>%
unite('file', Protection:Data)
View(to_exclude)
to_exclude <- all_protected_results %>%
group_by(Protection, Parameter, Model, Data) %>%
summarize(avg_AE = mean(values), .groups='drop') %>%
arrange(desc(avg_AE)) %>%
unite('file', Protection:Data) %>%
slice(1:11) %>%
pull(file)
# remove the large outlying errors
all_protected_results <- all_protected_results %>%
select(Protection, Parameter, Model, Data, Horizon, values) %>%
unite('file', Protection:Data) %>%
filter(!file %in% to_exclude) %>%
separate(file, c("Protection", "Parameter", "Model", "Data"), sep="_")
### calculate the average accuracy across all models and data sets
# for each privacy method
original_global_avg_mae <- all_original_results %>%
summarize(global_avg_MAE = mean(values)) %>%
pull(global_avg_MAE)
protection_avgs <- all_protected_results %>%
group_by(Protection, Parameter) %>%
summarize(global_avg_MAE = mean(values), .groups="drop") %>%
mutate(original_global_avg_MAE=original_global_avg_mae,
percent_change_mae = (global_avg_MAE-original_global_avg_MAE)/original_global_avg_MAE * 100) %>%
arrange(Protection, Parameter)
View(protection_avgs)
write.csv(protection_avgs, file=paste0("../../Outputs/Results/", data_folder, "Tables/protection_avgs.csv"), row.names=FALSE)
var_original_global_avg_mae <- all_original_results %>%
filter(Model == "VAR") %>%
summarize(global_avg_MAE = mean(values)) %>%
pull(global_avg_MAE)
var_protection_avgs <- var_protected_results %>%
group_by(Protection, Parameter) %>%
summarize(global_avg_MAE = mean(values), .groups="drop") %>%
mutate(original_global_avg_MAE=var_original_global_avg_mae,
percent_change_mae = (global_avg_MAE-original_global_avg_MAE)/original_global_avg_MAE * 100) %>%
arrange(Protection, Parameter)
View(var_protection_avgs)
original_model_ranks_mae <- all_original_results %>%
group_by(Model) %>%
summarize(MAE = mean(values)) %>%
arrange(MAE)
View(original_model_ranks_mae)
protected_model_ranks_mae <- all_protected_results %>%
filter(Protection == "k-nts-plus-bounded", Parameter == "3-1.5") %>%
group_by(Model) %>%
summarize(MAE = mean(values)) %>%
arrange(MAE)
View(protected_model_ranks_mae)
original_model_ranks_sd <- all_original_results %>%
group_by(Model) %>%
summarize(sd_MAE = sd(values)) %>%
arrange(sd_MAE)
View(original_model_ranks_sd)
### calculate overall average for each privacy method and data set
original_avg_data <- all_original_results %>%
group_by(Data) %>%
summarize(original_avg_mae = mean(values), .groups="drop")
protection_data_avgs <- all_protected_results %>%
group_by(Protection, Parameter, Data) %>%
summarize(avg_protected_mae = mean(values), .groups="drop") %>%
left_join(original_avg_data, by=c("Data")) %>%
mutate(pct_change_mae = (avg_protected_mae - original_avg_mae)/original_avg_mae * 100) %>%
arrange(Data)
write.csv(protection_data_avgs, paste0("../../Outputs/Results/", data_folder, "Tables/averages_by_frequency.csv"), row.names=FALSE)
# model specific results
original_model_avgs <- all_original_results %>%
group_by(Model) %>%
summarize(original_avg_mae = mean(values), .groups='drop')
protected_model_avgs <- all_protected_results %>%
filter(Protection == "k-nts-plus-bounded", Parameter == "3-1.5") %>%
group_by(Model) %>%
summarize(avg_mae = mean(values), .groups='drop')
model_avgs <- protected_model_avgs %>%
left_join(original_model_avgs, by="Model") %>%
mutate(pct_change = (avg_mae - original_avg_mae)/original_avg_mae * 100)
# data specific results
# model specific results
original_data_avgs <- all_original_results %>%
group_by(Data) %>%
summarize(original_avg_mae = mean(values), .groups='drop')
protected_data_avgs <- all_protected_results %>%
filter(Protection == "k-nts-plus-bounded", Parameter == "3-1.5") %>%
group_by(Data) %>%
summarize(avg_mae = mean(values), .groups='drop')
data_avgs <- protected_data_avgs %>%
left_join(original_data_avgs, by="Data") %>%
mutate(pct_change = (avg_mae - original_avg_mae)/original_avg_mae * 100)
write.csv(data_avgs, paste0("../../Outputs/Results/", data_folder, "Tables/k-nts-plus-3-1.5-averages_by_frequency.csv"), row.names=FALSE)
original_model_data_avgs <- all_original_results %>%
group_by(Model, Data) %>%
summarize(original_avg_mae = mean(values), .groups='drop')
protected_model_data_avgs <- all_protected_results %>%
filter(Protection == "k-nts-plus-bounded", Parameter == "3-1.5") %>%
group_by(Model, Data) %>%
summarize(avg_mae = mean(values), .groups='drop')
model_data_avgs <- protected_model_data_avgs %>%
left_join(original_model_data_avgs, by=c("Model", "Data")) %>%
mutate(pct_change = (avg_mae - original_avg_mae)/original_avg_mae * 100)
model_data_avgs %>%
ggplot(aes(x=Data, y=Model, fill=pct_change)) +
geom_tile(color = "white",
lwd = 1,
linetype = 1) +
geom_text(aes(label = round(pct_change)), color = "white", size = 3) +
# scale_fill_gradient(low = "darkgreen", high = "red") +
coord_fixed() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
text = element_text(size=19),
plot.title = element_text(face= "bold", colour= "black"),
axis.title.x = element_text(face="bold", colour = "black"),
axis.title.y = element_text(face="bold", colour = "black"))
setwd("C:/Users/Cameron/My Drive/Privacy-and-Forecasting-Empirical/Code/Analysis")
library(tidyverse)
library(ggpubr)
# import computation cost spreadsheets
fcast_times <- read_csv("../../Data/Computation_Time/M3_computation_time.csv")
knts_times <- read_csv("../../Data/Computation_Time/M3_k-nts-plus.csv")
# calculate how many time periods were swapped in total
# (num_series x num_periods)
data_folder = "M3/"
# paths to the data files and feature files
fp <- paste0("../../Data/Cleaned/", data_folder)
# import names of original data files - this may include protected versions
# so we have to remove those
file_names <- grep("_h1_train", list.files(fp), value=TRUE)
# make sure protected versions are excluded
file_names <- grep("AN_", file_names, value=TRUE, invert=TRUE)
file_names <- grep("DP_", file_names, value=TRUE, invert=TRUE)
file_names <- grep("k-nts", file_names, value=TRUE, invert=TRUE)
length_counts <- list()
lengths <- list()
for (f in seq_along(file_names)){
# import data and convert to a list of series
ts_data <- as.list(as.data.frame(t(read.csv(paste0(fp, file_names[f])))))
# remove NA values from the end of each series
ts_data <- lapply(ts_data, function(x) x[!is.na(x)])
# split into separate data sets, one for each series length
ls <- c()
lengths_temp <- sapply(ts_data, length)
unique_lengths <- unique(lengths_temp)
for (l in seq_along(unique_lengths)){
ls <- c(ls, sum(lengths_temp==unique_lengths[l]))
}
length_counts[[f]] <- ls
lengths[[f]] <- unique_lengths
}
# "num_swapped" is a vector containing how many time series values were
# swapped out
num_swapped <- c()
for (i in seq_along(length_counts)){
num_swapped <- c(num_swapped, sum(length_counts[[i]] * lengths[[i]]))
}
file_counts <- tibble(file_name = file_names,
num_swapped = num_swapped,
num_series = sapply(length_counts, sum),
avg_length = sapply(lengths, mean))
knts_times <- knts_times %>%
left_join(file_counts, by = c("File"="file_name"))
fcast_times <- fcast_times %>%
separate(File, c("Protection", "Parameter", "Data", "Horizon", "Data_Type"), sep="_")
sum_fcast_times <- fcast_times %>%
group_by(Data) %>%
summarize(across(Baseline.Protection.Time:feature_extraction, sum), .groups='drop') %>%
select(-num_series)
all_times <- knts_times %>%
mutate(Data = substr(File, start=1, stop=nchar(File)-13),
Seasonal = ifelse(grepl("monthly", Data), "Yes", ifelse(grepl("quarterly", Data), "Yes", "No"))) %>%
select(-File) %>%
left_join(sum_fcast_times, by=c("Data"))
total_times <- all_times %>%
gather(key="task", value="time", -num_swapped, -num_series, -avg_length, -Data, -Seasonal) %>%
group_by(Data, num_swapped, num_series, avg_length, Seasonal) %>%
summarize(total_time = sum(time), .groups='drop')
# what is the total time without the RNN model
total_times_no_rnn <- all_times %>%
select(-RNN_baseline) %>%
gather(key="task", value="time", -num_swapped, -num_series, -avg_length, -Data, -Seasonal) %>%
group_by(Data, num_swapped, num_series, avg_length, Seasonal) %>%
summarize(total_time = sum(time), .groups='drop') %>%
arrange(desc(total_time))
total_plot <- total_times %>%
ggplot(aes(x=num_swapped, y=total_time)) +
geom_point(size=2) +
geom_smooth(method='lm') +
labs(x = "Total Number Periods Swapped",
y = "Total Time (Seconds)",
title = "Total Computation Time vs. Total Number of Protected Time Periods") +
theme(plot.title = element_text(size=14, face= "bold", colour= "black" ),
axis.title.x = element_text(size=13, face="bold", colour = "black"),
axis.title.y = element_text(size=13, face="bold", colour = "black"))
## RReliefF as a function of number of series
relief_plot <- all_times %>%
ggplot(aes(x=num_series, y=RReliefF)) +
geom_point(size=2) +
geom_smooth(method='lm') +
labs(x = "Number of Time Series",
y = "Time (Seconds)",
title = "Total RReliefF Time vs. Number of Time Series")
## RReliefF as a function of number of series
rfe_plot <- all_times %>%
ggplot(aes(x=num_series, y=RFE)) +
geom_point(size=2) +
geom_smooth(method='lm') +
labs(x = "Number of Time Series",
y = "Time (Seconds)",
title = "Total RFE Time vs. Number of Time Series")
## Swapping time plot as a function of the number of time periods
swap_plot <- all_times %>%
ggplot(aes(x=avg_length, y=Swap)) +
geom_point(size=2) +
geom_smooth(method='lm') +
labs(x = "Number of Time Periods",
y = "Time (Seconds)",
title = "Total Swap Time vs. Average Series Length")
all_times %>%
ggplot(aes(x=num_series, y=Swap)) +
geom_point(size=2) +
geom_smooth(method='lm') +
labs(x = "Number of Time Periods",
y = "Time (Seconds)",
title = "Total Swap Time vs. Number of Time Periods")
all_times
# import computation cost spreadsheets
fcast_times <- read_csv("../../Data/Computation_Time/M3_computation_time.csv")
knts_times <- read_csv("../../Data/Computation_Time/M3_k-nts-plus.csv")
# calculate how many time periods were swapped in total
# (num_series x num_periods)
data_folder = "M3/"
# paths to the data files and feature files
fp <- paste0("../../Data/Cleaned/", data_folder)
# import names of original data files - this may include protected versions
# so we have to remove those
file_names <- grep("_h1_train", list.files(fp), value=TRUE)
# make sure protected versions are excluded
file_names <- grep("AN_", file_names, value=TRUE, invert=TRUE)
file_names <- grep("DP_", file_names, value=TRUE, invert=TRUE)
file_names <- grep("k-nts", file_names, value=TRUE, invert=TRUE)
length_counts <- list()
lengths <- list()
for (f in seq_along(file_names)){
# import data and convert to a list of series
ts_data <- as.list(as.data.frame(t(read.csv(paste0(fp, file_names[f])))))
# remove NA values from the end of each series
ts_data <- lapply(ts_data, function(x) x[!is.na(x)])
# split into separate data sets, one for each series length
ls <- c()
lengths_temp <- sapply(ts_data, length)
unique_lengths <- unique(lengths_temp)
for (l in seq_along(unique_lengths)){
ls <- c(ls, sum(lengths_temp==unique_lengths[l]))
}
length_counts[[f]] <- ls
lengths[[f]] <- unique_lengths
}
# "num_swapped" is a vector containing how many time series values were
# swapped out
num_swapped <- c()
for (i in seq_along(length_counts)){
num_swapped <- c(num_swapped, sum(length_counts[[i]] * lengths[[i]]))
}
file_counts <- tibble(file_name = file_names,
num_swapped = num_swapped,
num_series = sapply(length_counts, sum),
avg_length = sapply(lengths, mean))
knts_times <- knts_times %>%
left_join(file_counts, by = c("File"="file_name"))
knts_times
setwd("C:/Users/Cameron/My Drive/Privacy-and-Forecasting-Empirical/Code/Analysis")
##### Code to extract time series features for the original
##### and baseline protected data sets.
# Author: Cameron Bale
## NOTE: this file extracts features up through time period T-2 from the
# original and baseline protected data sets. These features are used to predict
# the forecast accuracy to perform feature selection for k-nTS+.
## Author: Cameron Bale
library(e1071)
library(tidyverse)
library(tsfeatures)
library(forecast)
source('custom_feature_functions.R')
data_folder <- "M3_rate/"
file_path <- paste0("../../Data/Cleaned/", data_folder)
# import names of original and baseline protected data files
file_names <- grep("_h1_train", list.files(file_path), value=TRUE)
file_names
#### compengine includes features in:
# autocorr_features
# pred_features
# station_features
# dist_features
# scal_features --> can't use this, some time series are too short
# also exclude arch.lm and arch_r2, they often return NA values
# vector of feature names to calculate
fv <- c("entropy_c", "lumpiness", "stability",
"max_level_shift_c", "max_var_shift_c", "max_kl_shift_c",
"crossing_points", "flat_spots", "hurst",
"unitroot_kpss", "unitroot_pp", "stl_features",
"acf_features", "pacf_features",
"nonlinearity", "series_mean", "series_variance",
"skewness", "kurtosis")
### Perform feature extraction for all original and baseline data sets.
################################################################################
################################################################################
################################################################################
################################################################################
for (f in file_names){
data_set <- read.csv(paste0(file_path, f))
sp_l <- ifelse(grepl("monthly", f), 12, ifelse(grepl("quarterly", f), 4, 1))
features <- extract_features(data_set, sp=sp_l, feature_vector=fv, truncate=FALSE, take_log=FALSE, calculate_cross_correlations=TRUE)
features <- features %>% select(-nperiods, -seasonal_period)
write.csv(features, file=paste0("../../Data/Features/", data_folder, "features_", f), row.names=FALSE)
}
setwd("C:/Users/Cameron/My Drive/Privacy-and-Forecasting-Empirical/Code/Analysis")
library(tidyverse)
library(forecast)
data_folder <- "M3_rate/"
# now import mean absolute errors for all forecasts
error_dist_path <- paste0("../../Outputs/Results/", data_folder, "Error_Distributions/")
# import results files
res_files <- list.files(error_dist_path)
res_files <- grep("_all_distributions_h1", res_files, value=TRUE)
res_files <- grep("inverse_rate", res_files, value=TRUE, invert=TRUE)
all_results <- lapply(res_files, function(x) read_csv(paste0(error_dist_path, x)))
# data frame for calculating protected results
all_protected_results <- lapply(all_results, function(x) x %>% select(contains("_DP_", ignore.case=FALSE),
contains("_AN_", ignore.case=FALSE),
contains("k-nts", ignore.case=FALSE)))
var_protected_results <- lapply(all_results, function(x) x %>% select(contains("var-an", ignore.case=FALSE),
contains("var-knts", ignore.case=FALSE),
contains("var-sim", ignore.case=FALSE)))
# data frame for calculating protected results
all_original_results <- lapply(all_results, function(x) x[,grep("_DP_", colnames(x[,grep("_AN_", colnames(x[,grep("k-nts", colnames(x[,grep("var-an", colnames(x[,grep("var-sim", colnames(x[,grep("var-knts", colnames(x), invert=TRUE, value=TRUE)]), invert=TRUE, value=TRUE)]), invert=TRUE, value=TRUE)]), invert=TRUE, value=TRUE)]), invert=TRUE, value=TRUE)]), invert=TRUE, value=TRUE)])
all_protected_results <- lapply(all_protected_results, function(x) bind_cols(x, Snum=1:nrow(x)))
var_protected_results <- lapply(var_protected_results, function(x) bind_cols(x, Snum=1:nrow(x)))
all_original_results <- lapply(all_original_results, function(x) bind_cols(x, Snum=1:nrow(x)))
# transform to tidy data
all_protected_results <- lapply(all_protected_results, function(x) x %>% gather(key="name", value="values", -Snum) %>%
mutate(name = substring(name, 1, nchar(name)-8)) %>%
separate(name, c("Model", "Horizon", "Protection", "Parameter", "Data_Type", "Data"), sep="_"))
var_protected_results <- lapply(var_protected_results, function(x) x %>% gather(key="name", value="values", -Snum) %>%
mutate(name = substring(name, 1, nchar(name)-8)) %>%
separate(name, c("Model", "Horizon", "Protection", "Parameter", "Data_Type", "Data"), sep="_"))
# transform to tidy data
all_original_results <- lapply(all_original_results, function(x) x %>% gather(key="name", value="values", -Snum) %>%
mutate(name = substring(name, 1, nchar(name)-8)) %>%
separate(name, c("Model", "Horizon", "Data_Type", "Data"), sep="_"))
# combine into a single dataframe
all_protected_results <- do.call(rbind, all_protected_results)
var_protected_results <- do.call(rbind, var_protected_results)
all_original_results <- do.call(rbind, all_original_results)
all_protected_results <- all_protected_results %>%
filter(Model != "VAR" | Data != "yearly-MICRO")
all_original_results <- all_original_results %>%
filter(Model != "VAR" | Data != "yearly-MICRO")
var_protected_results <- var_protected_results %>%
filter(Model != "VAR" | Data != "yearly-MICRO")
if (file.exists(paste0("../../Outputs/Results/", data_folder, "Tables/"))){
write.csv(all_original_results, file=paste0("../../Outputs/Results/", data_folder, "Tables/all_original_results.csv"), row.names = FALSE)
write.csv(all_protected_results, file=paste0("../../Outputs/Results/", data_folder, "Tables/all_protected_results.csv"), row.names = FALSE)
} else {
dir.create(paste0("../../Outputs/Results/", data_folder, "Tables/"))
write.csv(all_original_results, file=paste0("../../Outputs/Results/", data_folder, "Tables/all_original_results.csv"), row.names = FALSE)
write.csv(all_protected_results, file=paste0("../../Outputs/Results/", data_folder, "Tables/all_protected_results.csv"), row.names = FALSE)
}
### calculate the average accuracy across all models and data sets
# for each privacy method
original_global_avg_mae <- all_original_results %>%
summarize(global_avg_MAE = mean(values)) %>%
pull(global_avg_MAE)
var_original_global_avg_mae <- all_original_results %>%
filter(Model == "VAR") %>%
summarize(global_avg_MAE = mean(values)) %>%
pull(global_avg_MAE)
protection_avgs <- all_protected_results %>%
group_by(Protection, Parameter) %>%
summarize(global_avg_MAE = mean(values), .groups="drop") %>%
mutate(original_global_avg_MAE=original_global_avg_mae,
percent_change_mae = (global_avg_MAE-original_global_avg_MAE)/original_global_avg_MAE * 100) %>%
arrange(Protection, Parameter)
write.csv(protection_avgs, file=paste0("../../Outputs/Results/", data_folder, "Tables/rate_protection_avgs.csv"), row.names=FALSE)
View(protection_avgs)
var_protection_avgs <- var_protected_results %>%
group_by(Protection, Parameter) %>%
summarize(global_avg_MAE = mean(values), .groups="drop") %>%
mutate(original_global_avg_MAE=var_original_global_avg_mae,
percent_change_mae = (global_avg_MAE-original_global_avg_MAE)/original_global_avg_MAE * 100) %>%
arrange(Protection, Parameter)
View(var_protection_avgs)
# k-nTS+ (k = 3) model specific results
original_model_avgs <- all_original_results %>%
group_by(Model) %>%
summarize(original_avg_mae = mean(values), .groups='drop')
protected_model_avgs <- all_protected_results %>%
filter(Protection == "k-nts-plus", Parameter == "3") %>%
group_by(Model) %>%
summarize(avg_mae = mean(values), .groups='drop')
model_avgs <- protected_model_avgs %>%
left_join(original_model_avgs, by="Model") %>%
mutate(pct_change = (avg_mae - original_avg_mae)/original_avg_mae * 100)
View(model_avgs)
# import results files
ir_res_files <- list.files(error_dist_path)
ir_res_files <- grep("all_distributions_h1", ir_res_files, value=TRUE)
ir_res_files <- grep("inverse_rate", ir_res_files, value=TRUE)
all_ir_results <- lapply(ir_res_files, function(x) read_csv(paste0(error_dist_path, x)))
# data frame for calculating protected results
all_ir_protected_results <- lapply(all_ir_results, function(x) x %>% select(contains("_DP_", ignore.case=FALSE),
contains("_AN_", ignore.case=FALSE),
contains("k-nts", ignore.case=FALSE)))
var_ir_protected_results <- lapply(all_ir_results, function(x) x %>% select(contains("var-an", ignore.case=FALSE),
contains("var-knts", ignore.case=FALSE),
contains("var-sim", ignore.case=FALSE)))
# data frame for calculating protected results
all_ir_original_results <- lapply(all_ir_results, function(x) x[,grep("_DP_", colnames(x[,grep("_AN_", colnames(x[,grep("k-nts", colnames(x[,grep("var-an", colnames(x[,grep("var-sim", colnames(x[,grep("var-knts", colnames(x), invert=TRUE, value=TRUE)]), invert=TRUE, value=TRUE)]), invert=TRUE, value=TRUE)]), invert=TRUE, value=TRUE)]), invert=TRUE, value=TRUE)]), invert=TRUE, value=TRUE)])
all_ir_protected_results <- lapply(all_ir_protected_results, function(x) bind_cols(x, Snum=1:nrow(x)))
var_ir_protected_results <- lapply(var_ir_protected_results, function(x) bind_cols(x, Snum=1:nrow(x)))
all_ir_original_results <- lapply(all_ir_original_results, function(x) bind_cols(x, Snum=1:nrow(x)))
# transform to tidy data
all_ir_protected_results <- lapply(all_ir_protected_results, function(x) x %>% gather(key="name", value="values", -Snum) %>%
mutate(name = substring(name, 1, nchar(name)-8)) %>%
separate(name, c("Model", "Horizon", "Protection", "Parameter", "Data_Type", "Data"), sep="_"))
var_ir_protected_results <- lapply(var_ir_protected_results, function(x) x %>% gather(key="name", value="values", -Snum) %>%
mutate(name = substring(name, 1, nchar(name)-8)) %>%
separate(name, c("Model", "Horizon", "Protection", "Parameter", "Data_Type", "Data"), sep="_"))
# transform to tidy data
all_ir_original_results <- lapply(all_ir_original_results, function(x) x %>% gather(key="name", value="values", -Snum) %>%
mutate(name = substring(name, 1, nchar(name)-8)) %>%
separate(name, c("Model", "Horizon", "Data_Type", "Data"), sep="_"))
# combine into a single dataframe
all_ir_protected_results <- do.call(rbind, all_ir_protected_results)
var_ir_protected_results <- do.call(rbind, var_ir_protected_results)
all_ir_original_results <- do.call(rbind, all_ir_original_results)
all_ir_protected_results <- all_ir_protected_results %>%
filter(Model != "VAR" | Data != "yearly-MICRO")
all_ir_original_results <- all_ir_original_results %>%
filter(Model != "VAR" | Data != "yearly-MICRO")
var_ir_protected_results <- var_ir_protected_results %>%
filter(Model != "VAR" | Data != "yearly-MICRO")
if (file.exists(paste0("../../Outputs/Results/", data_folder, "Tables/"))){
write.csv(all_ir_protected_results, file=paste0("../../Outputs/Results/", data_folder, "Tables/all_ir_protected_results.csv"), row.names = FALSE)
} else {
dir.create(paste0("../../Outputs/Results/", data_folder, "Tables/"))
write.csv(all_ir_protected_results, file=paste0("../../Outputs/Results/", data_folder, "Tables/all_ir_protected_results.csv"), row.names = FALSE)
}
### calculate the average accuracy across all models and data sets
# for each privacy method
original_m3_results <- read.csv("../../Outputs/Results/M3/Tables/all_original_results.csv")
ir_original_global_avg_mae <- original_m3_results %>%
summarize(global_avg_MAE = mean(values)) %>%
pull(global_avg_MAE)
ir_original_var_global_avg_mae <- original_m3_results %>%
filter(Model == "VAR") %>%
summarize(global_avg_MAE = mean(values)) %>%
pull(global_avg_MAE)
ir_original_avgs <- all_ir_original_results %>%
summarize(global_avg_MAE = mean(values), .groups="drop") %>%
mutate(original_global_avg_MAE=ir_original_global_avg_mae,
percent_change_mae = (global_avg_MAE-original_global_avg_MAE)/original_global_avg_MAE * 100)
original_model_avgs <- original_m3_results %>%
group_by(Model) %>%
summarize(original_global_avg_MAE = mean(values))
ir_original_model_avgs <- all_ir_original_results %>%
group_by(Model) %>%
summarize(global_avg_MAE = mean(values), .groups="drop") %>%
left_join(original_model_avgs, by = "Model") %>%
mutate(percent_change_mae = (global_avg_MAE-original_global_avg_MAE)/original_global_avg_MAE * 100)
ir_protection_avgs <- all_ir_protected_results %>%
group_by(Protection, Parameter) %>%
summarize(global_avg_MAE = mean(values), .groups="drop") %>%
mutate(original_global_avg_MAE=ir_original_global_avg_mae,
percent_change_mae = (global_avg_MAE-original_global_avg_MAE)/original_global_avg_MAE * 100) %>%
arrange(Protection, Parameter)
write.csv(ir_protection_avgs, file=paste0("../../Outputs/Results/", data_folder, "Tables/ir_rate_protection_avgs.csv"), row.names=FALSE)
View(ir_protection_avgs)
ir_var_protection_avgs <- var_ir_protected_results %>%
group_by(Protection, Parameter) %>%
summarize(global_avg_MAE = mean(values), .groups="drop") %>%
mutate(original_global_avg_MAE=ir_original_var_global_avg_mae,
percent_change_mae = (global_avg_MAE-original_global_avg_MAE)/original_global_avg_MAE * 100) %>%
arrange(Protection, Parameter)
View(ir_var_protection_avgs)
# model specific results
original_ir_model_avgs <- original_m3_results %>%
group_by(Model) %>%
summarize(original_avg_mae = mean(values), .groups='drop')
protected_ir_model_avgs <- all_ir_protected_results %>%
filter(Protection == "k-nts-plus", Parameter == "3") %>%
group_by(Model) %>%
summarize(avg_mae = mean(values), .groups='drop')
ir_model_avgs <- protected_ir_model_avgs %>%
left_join(original_ir_model_avgs, by="Model") %>%
mutate(pct_change = (avg_mae - original_avg_mae)/original_avg_mae * 100)
