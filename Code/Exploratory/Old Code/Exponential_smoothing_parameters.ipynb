{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02dc42c8",
   "metadata": {},
   "source": [
    "## Code to Extract Exponential Smoothing Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0982b099",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3ecf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules\n",
    "import statsmodels.tsa.holtwinters as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d315e1ee",
   "metadata": {},
   "source": [
    "We need to read in each protected dataset, fit the exponential smoothing models, and extract the parameters for each series. Save these as a dataset, and plot in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c03b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results file path\n",
    "results_path = \"../../Outputs/Results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22ca815",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../../Data/Train/Clean/m3_monthly_micro_h1.csv\", header=None, skiprows=1)\n",
    "# convert to a list of series, and drop missing values\n",
    "train_data = [x.dropna() for _, x in train_data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc3d5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"../../Data/Train/Clean/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96ca8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in files if (\"protected_m3_monthly_micro_h1_\" in f or \"full_m3\" in f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d09c99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['full_m3_monthly_micro_clean.csv',\n",
       " 'protected_m3_monthly_micro_h1_AN_0.25.csv',\n",
       " 'protected_m3_monthly_micro_h1_AN_0.5.csv',\n",
       " 'protected_m3_monthly_micro_h1_AN_1.5.csv',\n",
       " 'protected_m3_monthly_micro_h1_AN_1.csv',\n",
       " 'protected_m3_monthly_micro_h1_AN_2.csv',\n",
       " 'protected_m3_monthly_micro_h1_Bottom_0.1.csv',\n",
       " 'protected_m3_monthly_micro_h1_Bottom_0.2.csv',\n",
       " 'protected_m3_monthly_micro_h1_Bottom_0.4.csv',\n",
       " 'protected_m3_monthly_micro_h1_DP_0.1.csv',\n",
       " 'protected_m3_monthly_micro_h1_DP_1.csv',\n",
       " 'protected_m3_monthly_micro_h1_DP_10.csv',\n",
       " 'protected_m3_monthly_micro_h1_DP_20.csv',\n",
       " 'protected_m3_monthly_micro_h1_DP_4.6.csv',\n",
       " 'protected_m3_monthly_micro_h1_k-nts-plus_10.csv',\n",
       " 'protected_m3_monthly_micro_h1_k-nts-plus_15.csv',\n",
       " 'protected_m3_monthly_micro_h1_k-nts-plus_3.csv',\n",
       " 'protected_m3_monthly_micro_h1_k-nts-plus_5.csv',\n",
       " 'protected_m3_monthly_micro_h1_k-nts-plus_7.csv',\n",
       " 'protected_m3_monthly_micro_h1_k-nts_10.csv',\n",
       " 'protected_m3_monthly_micro_h1_k-nts_15.csv',\n",
       " 'protected_m3_monthly_micro_h1_k-nts_3.csv',\n",
       " 'protected_m3_monthly_micro_h1_k-nts_5.csv',\n",
       " 'protected_m3_monthly_micro_h1_k-nts_7.csv',\n",
       " 'protected_m3_monthly_micro_h1_Top_0.1.csv',\n",
       " 'protected_m3_monthly_micro_h1_Top_0.2.csv',\n",
       " 'protected_m3_monthly_micro_h1_Top_0.4.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c56c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\"full\":[], \n",
    "           \"AN\": [0.25, 0.5, 1, 1.5, 2], \n",
    "           \"DP\": [0.1, 1, 4.6, 10, 20],  \n",
    "           \"k-nts\": [3, 5, 7, 10, 15],\n",
    "           \"k-nts-plus\": [3, 5, 7, 10, 15]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b60d3bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_dict = {}\n",
    "des_dict = {}\n",
    "tes_dict = {}\n",
    "\n",
    "for method in methods.items():\n",
    "    method_files = [f for f in files if method[0]+\"_\" in f]\n",
    "    \n",
    "    if method[0] == \"full\":\n",
    "        param_files = method_files\n",
    "        [param_files] = param_files\n",
    "        \n",
    "        full_data = pd.read_csv(\"../../Data/Train/Clean/\"+param_files, header=None, skiprows=1)\n",
    "        full_data = [x.dropna() for _, x in full_data.iterrows()]\n",
    "        full_data = [pd.Series([i if i >= 1 else 1 for i in x]) for x in full_data]\n",
    "        full_data = [np.log(x) for x in full_data]\n",
    "        \n",
    "        ses_params = []\n",
    "        ses_levels = []\n",
    "        des_params = []\n",
    "        des_levels = []\n",
    "        des_trends = []\n",
    "        des_keys = ['smoothing_level', 'smoothing_trend']\n",
    "        tes_params = []\n",
    "        tes_levels = []\n",
    "        tes_trends = []\n",
    "        tes_seasons = []\n",
    "        tes_keys = ['smoothing_level', 'smoothing_trend', 'smoothing_seasonal']\n",
    "        \n",
    "        for x in full_data:\n",
    "            SES = sm.ExponentialSmoothing(endog=x)\n",
    "            DES = sm.ExponentialSmoothing(endog=x, trend=\"additive\")\n",
    "            TES = sm.ExponentialSmoothing(endog=x, trend=\"additive\", seasonal=\"additive\", seasonal_periods=12)\n",
    "            ses = SES.fit()\n",
    "            des = DES.fit()\n",
    "            tes = TES.fit()\n",
    "            ses_params.append(ses.params['smoothing_level'])\n",
    "            ses_levels.append(np.mean(ses.level))\n",
    "            des_params.append({key:value for key,value in des.params.items() if key in des_keys})\n",
    "            des_levels.append(np.mean(des.level))\n",
    "            des_trends.append(np.mean(des.trend))\n",
    "            tes_params.append({key:value for key,value in tes.params.items() if key in tes_keys})\n",
    "            tes_levels.append(np.mean(tes.level))\n",
    "            tes_trends.append(np.mean(tes.trend))\n",
    "            tes_seasons.append(np.mean(tes.season))\n",
    "            \n",
    "        ses_dict['original_none_alpha'] = ses_params\n",
    "        ses_dict['original_none_level'] = ses_levels\n",
    "        des_dict['original_none_alpha'] = [x['smoothing_level'] for x in des_params]\n",
    "        des_dict['original_none_beta'] = [x['smoothing_trend'] for x in des_params]\n",
    "        des_dict['original_none_level'] = des_levels\n",
    "        des_dict['original_none_trend'] = des_trends\n",
    "        tes_dict['original_none_alpha'] = [x['smoothing_level'] for x in tes_params]\n",
    "        tes_dict['original_none_beta'] = [x['smoothing_trend'] for x in tes_params]\n",
    "        tes_dict['original_none_gamma'] = [x['smoothing_seasonal'] for x in tes_params]\n",
    "        tes_dict['original_none_level'] = tes_levels\n",
    "        tes_dict['original_none_trend'] = tes_trends\n",
    "        tes_dict['original_none_season'] = tes_seasons\n",
    "    \n",
    "    else: \n",
    "        for param in method[1]:\n",
    "            param_files = [f for f in method_files if \"_\"+str(param)+\".csv\" in f]\n",
    "            [param_files] = param_files\n",
    "            \n",
    "            full_data = pd.read_csv(\"../../Data/Train/Clean/\"+param_files, header=None, skiprows=1)\n",
    "            full_data = [x.dropna() for _, x in full_data.iterrows()]\n",
    "            full_data = [pd.Series([i if i >= 1 else 1 for i in x]) for x in full_data]\n",
    "            full_data = [np.log(x) for x in full_data]\n",
    "            \n",
    "            ses_params = []\n",
    "            ses_levels = []\n",
    "            des_params = []\n",
    "            des_levels = []\n",
    "            des_trends = []\n",
    "            tes_params = []\n",
    "            tes_levels = []\n",
    "            tes_trends = []\n",
    "            tes_seasons = []\n",
    "            \n",
    "            for x in full_data:\n",
    "                SES = sm.ExponentialSmoothing(endog=x)\n",
    "                DES = sm.ExponentialSmoothing(endog=x, trend=\"additive\")\n",
    "                TES = sm.ExponentialSmoothing(endog=x, trend=\"additive\", seasonal=\"additive\", seasonal_periods=12)\n",
    "                ses = SES.fit()\n",
    "                des = DES.fit()\n",
    "                tes = TES.fit()\n",
    "                ses_params.append(ses.params['smoothing_level'])\n",
    "                ses_levels.append(np.mean(ses.level))\n",
    "                des_params.append({key:value for key,value in des.params.items() if key in des_keys})\n",
    "                des_levels.append(np.mean(des.level))\n",
    "                des_trends.append(np.mean(des.trend))\n",
    "                tes_params.append({key:value for key,value in tes.params.items() if key in tes_keys})\n",
    "                tes_levels.append(np.mean(tes.level))\n",
    "                tes_trends.append(np.mean(tes.trend))\n",
    "                tes_seasons.append(np.mean(tes.season))\n",
    "            \n",
    "            ses_dict[method[0]+'_'+str(param)+'_alpha'] = np.array(ses_params)\n",
    "            ses_dict[method[0]+'_'+str(param)+'_level'] = np.array(ses_levels)\n",
    "            des_dict[method[0]+'_'+str(param)+'_alpha'] = np.array([x['smoothing_level'] for x in des_params])\n",
    "            des_dict[method[0]+'_'+str(param)+'_beta'] = np.array([x['smoothing_trend'] for x in des_params])\n",
    "            des_dict[method[0]+'_'+str(param)+'_level'] = des_levels\n",
    "            des_dict[method[0]+'_'+str(param)+'_trend'] = des_trends\n",
    "            tes_dict[method[0]+'_'+str(param)+'_alpha'] = np.array([x['smoothing_level'] for x in tes_params])\n",
    "            tes_dict[method[0]+'_'+str(param)+'_beta'] = np.array([x['smoothing_trend'] for x in tes_params])\n",
    "            tes_dict[method[0]+'_'+str(param)+'_gamma'] = np.array([x['smoothing_seasonal'] for x in tes_params])\n",
    "            tes_dict[method[0]+'_'+str(param)+'_level'] = tes_levels\n",
    "            tes_dict[method[0]+'_'+str(param)+'_trend'] = tes_trends\n",
    "            tes_dict[method[0]+'_'+str(param)+'_season'] = tes_seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1335c51",
   "metadata": {},
   "source": [
    "Now save parameter dictionaries as dataframes for analysis in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f7fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ses_dict).to_csv(results_path+\"Model Parameters/ses_params.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7b65f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(des_dict).to_csv(results_path+\"Model Parameters/des_params.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b9fc917",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tes_dict).to_csv(results_path+\"Model Parameters/tes_params.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a009ac5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
