{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning M4 data: Weekly Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code imports the weekly level time series used in the [M4](https://www.sciencedirect.com/journal/international-journal-of-forecasting/vol/36/issue/1) competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Breakdown**\n",
    "\n",
    "* One dataset per data frequency:\n",
    "    - Yearly\n",
    "    - Quarterly\n",
    "    - Monthly\n",
    "    - Weekly\n",
    "    - Daily\n",
    "    - Hourly\n",
    "* Each dataset contains series from at least one domain:\n",
    "    - Micro\n",
    "    - Industry\n",
    "    - Macro\n",
    "    - Finance\n",
    "    - Demographic\n",
    "    - Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Using this dataset for the paper would allow us to examine not only the effects of data protection on the accuracy of various forecasting models, but how those effects interact with the traits of the data being forecasted (data frequency, domain, seasonality, trend, etc.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data for Initial Modeling**\n",
    "\n",
    "For the purposes of getting the forecasting models and protection methods implemented, we select the series from one data frequency and one domain. The `Weekly` frequency `Finance` domain contains 164 series which seems to be a reasonable number to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "* **Step 1**: Import weekly training data file `Weekly-train.csv` and `M4-info.csv` which identifies time series within each domain (e.g., Finance, Micro, etc.)\n",
    "* **Step 2**: Using the series identifiers in `M4-info.csv`, select the `Finance` series from the `Weekly-train.csv` dataset.\n",
    "* **Step 3**: Remove any time periods that contain missing values for any series - *we will take this step out in the future and will forecast the M4 testing data using all available training data*.\n",
    "* **Step 4**: Save the `Weekly` domain `Finance` series to a `.csv` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training data for weekly time series\n",
    "weekly_train = pd.read_csv(\"../../../Data/Train/Weekly-train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import identifying file for time series\n",
    "m4_info = pd.read_csv(\"../../../Data/M4-info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using information from the M4 paper, we know there are 164 weekly level time series from the Finance domain. This seems like a decent number for initially implementing our models and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store ids for Weekly time series in Micro category\n",
    "time_freq = \"Weekly\"\n",
    "sector = \"Finance\"\n",
    "ts_ids = m4_info.loc[(m4_info.SP == time_freq) & (m4_info.category == sector),:][\"M4id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset weekly time series data for Finance domain\n",
    "ts = weekly_train.loc[weekly_train.V1.isin(ts_ids),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sum the number of NA values in each column\n",
    "# # use to remove any column with missing values\n",
    "# ts = ts.loc[:, ts.isna().sum() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 2598)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are left with 164 series with 247 (one column is row names) measurements in each. Save the file with the row ID's removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.iloc[:, 1:].to_csv(\"../../../Data/Train/Clean/full_m4_weekly_finance_clean.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
