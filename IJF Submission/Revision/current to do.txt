Start k-nTS+ on M4 data. --> done.

Start k-nTS+ using my hypothesized version. (scaling and tsoutliers removal)

Compute series level spectral entropy, distance to nearest neighbors on selected features, and change in forecast accuracy. Predict accuracy/visualize.









Start k-nTS+ with synthetic time series. Think about scaling the synthetic series???

Is there some sort of fuzzy k-anonymity we can apply to the features data? A metric based on feature similarity?

Relate it to the literature on k-anonymity and the difficulty of anonymization in higher dimensions. k-anonymity
struggles with the curse of dimensionality and there are dozens of potentially identifying features.

Need to calculate series-level privacy and relate that to feature and value similarity. We would expect to find that time series that are the least similar are also the least private.




** run k-nTS+ using the synthetic time series, generate forecasts, then send results (privacy and forecast accuracy)




** use t-SNE to visualize the within-dataset similarity. Reference GRATIS paper, it talks about PCA only being linear.

** look at series level privacy results - compare to feature similarity and forecast accuracy

** run k-nTS+ on M4

** what if it's the features that are most important for predicting forecast accuracy that determine whether we can
successfully swap and maintain forecast accuracy? Maybe some features can't be maintained?

** test with normalizing and k-nTS+



Tonight:

-implement measuring accuracy with MASE
-send t-SNE results


